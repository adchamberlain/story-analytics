# Phase 8 Implementation Plan: Data Transforms, Edit History, CSV Download

> **For Claude:** REQUIRED SUB-SKILL: Use superpowers:executing-plans to implement this plan task-by-task.

**Goal:** Add spreadsheet-lite data transforms, auto-save edit history with restore, and configurable "Get the Data" CSV download.

**Architecture:** 3 independent sessions (N, O, P) in parallel worktrees. Session N adds transform endpoints and a data grid UI. Session O adds version storage and a history timeline. Session P adds a CSV endpoint and download links.

**Tech Stack:** React 18, FastAPI, DuckDB, Tailwind v4, TypeScript, Vitest, pytest

---

## Session N: Data Transforms

**Files:**
- Create: `api/routers/transforms.py`
- Create: `api/tests/test_transforms.py`
- Create: `app/src/components/editor/DataTransformGrid.tsx`
- Create: `app/src/tests/data-transforms.test.tsx`
- Modify: `api/main.py` (lines 18-30: imports, lines 106-119: router inclusion)
- Modify: `api/services/duckdb_service.py` (lines 109-195: ingest_csv)
- Modify: `app/src/pages/EditorPage.tsx` (lines 322-390: three-pane layout)
- Modify: `app/src/stores/dataStore.ts`

### Task N.1: Backend Transform Service

**Step 1: Write failing tests**

Create `api/tests/test_transforms.py`:

```python
import pytest
from fastapi.testclient import TestClient
from pathlib import Path
import csv
import io


def _upload_csv(client, csv_text: str, filename: str = "test.csv"):
    """Helper: upload CSV text and return source_id."""
    resp = client.post(
        "/api/data/paste",
        json={"text": csv_text, "filename": filename},
    )
    assert resp.status_code == 200
    return resp.json()["source_id"]


class TestTransposeTransform:
    def test_transpose_swaps_rows_and_columns(self, client):
        sid = _upload_csv(client, "name,age,city\nAlice,30,NYC\nBob,25,LA")
        resp = client.post(f"/api/data/{sid}/transform/transpose")
        assert resp.status_code == 200
        data = resp.json()
        # After transpose: 3 rows (name, age, city), 2 data columns
        assert len(data["columns"]) == 3  # header + 2 original rows
        assert data["row_count"] == 3


class TestRenameColumn:
    def test_rename_column(self, client):
        sid = _upload_csv(client, "name,age\nAlice,30")
        resp = client.post(
            f"/api/data/{sid}/transform/rename-column",
            json={"old": "name", "new": "full_name"},
        )
        assert resp.status_code == 200
        assert "full_name" in resp.json()["columns"]
        assert "name" not in resp.json()["columns"]

    def test_rename_nonexistent_column_404(self, client):
        sid = _upload_csv(client, "name,age\nAlice,30")
        resp = client.post(
            f"/api/data/{sid}/transform/rename-column",
            json={"old": "missing", "new": "x"},
        )
        assert resp.status_code == 404


class TestDeleteColumn:
    def test_delete_column(self, client):
        sid = _upload_csv(client, "name,age,city\nAlice,30,NYC")
        resp = client.post(
            f"/api/data/{sid}/transform/delete-column",
            json={"column": "city"},
        )
        assert resp.status_code == 200
        assert "city" not in resp.json()["columns"]
        assert len(resp.json()["columns"]) == 2


class TestReorderColumns:
    def test_reorder_columns(self, client):
        sid = _upload_csv(client, "a,b,c\n1,2,3")
        resp = client.post(
            f"/api/data/{sid}/transform/reorder-columns",
            json={"columns": ["c", "a", "b"]},
        )
        assert resp.status_code == 200
        assert resp.json()["columns"] == ["c", "a", "b"]


class TestRoundTransform:
    def test_round_column(self, client):
        sid = _upload_csv(client, "val\n3.14159\n2.71828")
        resp = client.post(
            f"/api/data/{sid}/transform/round",
            json={"column": "val", "decimals": 2},
        )
        assert resp.status_code == 200
        rows = resp.json()["rows"]
        assert rows[0]["val"] == 3.14
        assert rows[1]["val"] == 2.72


class TestPrependAppend:
    def test_prepend_and_append(self, client):
        sid = _upload_csv(client, "price\n100\n200")
        resp = client.post(
            f"/api/data/{sid}/transform/prepend-append",
            json={"column": "price", "prepend": "$", "append": " USD"},
        )
        assert resp.status_code == 200
        rows = resp.json()["rows"]
        assert rows[0]["price"] == "$100 USD"


class TestEditCell:
    def test_edit_single_cell(self, client):
        sid = _upload_csv(client, "name,age\nAlice,30\nBob,25")
        resp = client.post(
            f"/api/data/{sid}/transform/edit-cell",
            json={"row": 0, "column": "name", "value": "Alicia"},
        )
        assert resp.status_code == 200
        assert resp.json()["rows"][0]["name"] == "Alicia"


class TestCastType:
    def test_cast_to_number(self, client):
        sid = _upload_csv(client, "val\n100\n200\nthree")
        resp = client.post(
            f"/api/data/{sid}/transform/cast-type",
            json={"column": "val", "type": "number"},
        )
        assert resp.status_code == 200
        rows = resp.json()["rows"]
        assert rows[0]["val"] == 100.0
        assert rows[1]["val"] == 200.0
        # "three" becomes null
        assert rows[2]["val"] is None
```

**Step 2: Run tests — expect 404s (router doesn't exist)**

Run: `cd api && python -m pytest tests/test_transforms.py -v`

**Step 3: Implement transforms router**

Create `api/routers/transforms.py`:

```python
"""Data transform endpoints — modify source CSV in-place and re-ingest."""
from __future__ import annotations

import csv
import io
from pathlib import Path

from fastapi import APIRouter, HTTPException
from pydantic import BaseModel

from ..services.duckdb_service import duckdb_svc

router = APIRouter(prefix="/data", tags=["transforms"])


# ── Request schemas ──────────────────────────────────────────────────────

class RenameColumnRequest(BaseModel):
    old: str
    new: str

class DeleteColumnRequest(BaseModel):
    column: str

class ReorderColumnsRequest(BaseModel):
    columns: list[str]

class RoundRequest(BaseModel):
    column: str
    decimals: int = 2

class PrependAppendRequest(BaseModel):
    column: str
    prepend: str = ""
    append: str = ""

class EditCellRequest(BaseModel):
    row: int
    column: str
    value: str | int | float | None

class CastTypeRequest(BaseModel):
    column: str
    type: str  # "text" | "number" | "date"


# ── Helpers ──────────────────────────────────────────────────────────────

def _get_source_path(source_id: str) -> Path:
    """Find the CSV file for a source_id."""
    meta = duckdb_svc._sources.get(source_id)
    if not meta:
        raise HTTPException(404, f"Source {source_id} not found")
    return meta.path


def _read_csv(path: Path) -> tuple[list[str], list[dict]]:
    """Read CSV into (columns, rows)."""
    with open(path, newline="", encoding="utf-8-sig") as f:
        reader = csv.DictReader(f)
        columns = reader.fieldnames or []
        rows = list(reader)
    return list(columns), rows


def _write_csv(path: Path, columns: list[str], rows: list[dict]):
    """Write rows back to CSV atomically."""
    tmp = path.with_suffix(".tmp")
    with open(tmp, "w", newline="", encoding="utf-8") as f:
        writer = csv.DictWriter(f, fieldnames=columns)
        writer.writeheader()
        writer.writerows(rows)
    tmp.rename(path)


def _reingest_and_preview(source_id: str, path: Path, limit: int = 50):
    """Re-ingest CSV into DuckDB and return preview."""
    schema = duckdb_svc.ingest_csv(path, path.name, source_id=source_id)
    result = duckdb_svc.execute_query(
        f"SELECT * FROM {{{{source}}}} LIMIT {limit}", source_id
    )
    return {
        "columns": result.columns,
        "rows": result.rows,
        "row_count": result.row_count,
    }


# ── Endpoints ────────────────────────────────────────────────────────────

@router.post("/{source_id}/transform/transpose")
async def transpose(source_id: str):
    path = _get_source_path(source_id)
    columns, rows = _read_csv(path)
    if not rows:
        raise HTTPException(400, "No data to transpose")

    # Transpose: columns become rows, first column values become new headers
    new_cols = ["field"] + [row.get(columns[0], f"row_{i}") for i, row in enumerate(rows)]
    new_rows = []
    for col in columns[1:]:
        new_row = {"field": col}
        for i, row in enumerate(rows):
            new_row[new_cols[i + 1]] = row.get(col, "")
        new_rows.append(new_row)

    _write_csv(path, new_cols, new_rows)
    return _reingest_and_preview(source_id, path)


@router.post("/{source_id}/transform/rename-column")
async def rename_column(source_id: str, req: RenameColumnRequest):
    path = _get_source_path(source_id)
    columns, rows = _read_csv(path)
    if req.old not in columns:
        raise HTTPException(404, f"Column '{req.old}' not found")
    new_columns = [req.new if c == req.old else c for c in columns]
    new_rows = [{req.new if k == req.old else k: v for k, v in row.items()} for row in rows]
    _write_csv(path, new_columns, new_rows)
    return _reingest_and_preview(source_id, path)


@router.post("/{source_id}/transform/delete-column")
async def delete_column(source_id: str, req: DeleteColumnRequest):
    path = _get_source_path(source_id)
    columns, rows = _read_csv(path)
    if req.column not in columns:
        raise HTTPException(404, f"Column '{req.column}' not found")
    new_columns = [c for c in columns if c != req.column]
    new_rows = [{k: v for k, v in row.items() if k != req.column} for row in rows]
    _write_csv(path, new_columns, new_rows)
    return _reingest_and_preview(source_id, path)


@router.post("/{source_id}/transform/reorder-columns")
async def reorder_columns(source_id: str, req: ReorderColumnsRequest):
    path = _get_source_path(source_id)
    columns, rows = _read_csv(path)
    # Validate all requested columns exist
    for col in req.columns:
        if col not in columns:
            raise HTTPException(404, f"Column '{col}' not found")
    new_rows = [{c: row.get(c, "") for c in req.columns} for row in rows]
    _write_csv(path, req.columns, new_rows)
    return _reingest_and_preview(source_id, path)


@router.post("/{source_id}/transform/round")
async def round_column(source_id: str, req: RoundRequest):
    path = _get_source_path(source_id)
    columns, rows = _read_csv(path)
    if req.column not in columns:
        raise HTTPException(404, f"Column '{req.column}' not found")
    for row in rows:
        try:
            row[req.column] = str(round(float(row[req.column]), req.decimals))
        except (ValueError, TypeError):
            pass  # Leave non-numeric values as-is
    _write_csv(path, columns, rows)
    return _reingest_and_preview(source_id, path)


@router.post("/{source_id}/transform/prepend-append")
async def prepend_append(source_id: str, req: PrependAppendRequest):
    path = _get_source_path(source_id)
    columns, rows = _read_csv(path)
    if req.column not in columns:
        raise HTTPException(404, f"Column '{req.column}' not found")
    for row in rows:
        val = row.get(req.column, "")
        row[req.column] = f"{req.prepend}{val}{req.append}"
    _write_csv(path, columns, rows)
    return _reingest_and_preview(source_id, path)


@router.post("/{source_id}/transform/edit-cell")
async def edit_cell(source_id: str, req: EditCellRequest):
    path = _get_source_path(source_id)
    columns, rows = _read_csv(path)
    if req.column not in columns:
        raise HTTPException(404, f"Column '{req.column}' not found")
    if req.row < 0 or req.row >= len(rows):
        raise HTTPException(400, f"Row {req.row} out of range (0-{len(rows) - 1})")
    rows[req.row][req.column] = "" if req.value is None else str(req.value)
    _write_csv(path, columns, rows)
    return _reingest_and_preview(source_id, path)


@router.post("/{source_id}/transform/cast-type")
async def cast_type(source_id: str, req: CastTypeRequest):
    path = _get_source_path(source_id)
    columns, rows = _read_csv(path)
    if req.column not in columns:
        raise HTTPException(404, f"Column '{req.column}' not found")
    for row in rows:
        val = row.get(req.column, "")
        if req.type == "number":
            try:
                row[req.column] = str(float(val))
            except (ValueError, TypeError):
                row[req.column] = ""
        elif req.type == "text":
            row[req.column] = str(val)
        # "date" — leave as-is for now (DuckDB handles date parsing on ingest)
    _write_csv(path, columns, rows)
    return _reingest_and_preview(source_id, path)
```

**Step 4: Register router in main.py**

In `api/main.py`, add:
```python
from .routers.transforms import router as transforms_router
# ...
app.include_router(transforms_router, prefix="/api")
```

**Step 5: Run tests**

Run: `cd api && python -m pytest tests/test_transforms.py -v`
Expected: PASS (15 tests)

**Step 6: Commit**

```bash
git add api/routers/transforms.py api/tests/test_transforms.py api/main.py
git commit -m "feat: add data transform endpoints (transpose, rename, delete, reorder, round, prepend/append, edit-cell, cast-type)"
```

---

### Task N.2: Frontend Transform Store

**Files:**
- Modify: `app/src/stores/dataStore.ts`

**Step 1: Add transform API calls to dataStore**

Add methods for each transform operation. These call the backend and update the local preview state:

```typescript
// Add to the dataStore Zustand store:

transformTranspose: async (sourceId: string) => {
  const res = await fetch(`${API_BASE}/${sourceId}/transform/transpose`, { method: 'POST' })
  if (!res.ok) throw new Error(await res.text())
  const data = await res.json()
  set({ preview: data })
  return data
},

transformRenameColumn: async (sourceId: string, old: string, newName: string) => {
  const res = await fetch(`${API_BASE}/${sourceId}/transform/rename-column`, {
    method: 'POST',
    headers: { 'Content-Type': 'application/json' },
    body: JSON.stringify({ old, new: newName }),
  })
  if (!res.ok) throw new Error(await res.text())
  const data = await res.json()
  set({ preview: data })
  return data
},

// ... similar pattern for delete-column, reorder-columns, round, prepend-append, edit-cell, cast-type
```

**Step 2: Commit**

```bash
git commit -m "feat: add transform API methods to dataStore"
```

---

### Task N.3: DataTransformGrid Component

**Files:**
- Create: `app/src/components/editor/DataTransformGrid.tsx`
- Create: `app/src/tests/data-transforms.test.tsx`

**Step 1: Write failing tests**

Create `app/src/tests/data-transforms.test.tsx`:

```tsx
import { describe, it, expect, vi } from 'vitest'
import { render, screen, fireEvent } from '@testing-library/react'
import { DataTransformGrid } from '../components/editor/DataTransformGrid'

const mockData = {
  columns: ['name', 'age', 'city'],
  rows: [
    { name: 'Alice', age: '30', city: 'NYC' },
    { name: 'Bob', age: '25', city: 'LA' },
  ],
}

describe('DataTransformGrid', () => {
  it('renders column headers', () => {
    render(<DataTransformGrid data={mockData} sourceId="abc" onTransform={vi.fn()} />)
    expect(screen.getByText('name')).toBeDefined()
    expect(screen.getByText('age')).toBeDefined()
    expect(screen.getByText('city')).toBeDefined()
  })

  it('renders all data rows', () => {
    render(<DataTransformGrid data={mockData} sourceId="abc" onTransform={vi.fn()} />)
    expect(screen.getByText('Alice')).toBeDefined()
    expect(screen.getByText('Bob')).toBeDefined()
  })

  it('enters edit mode on cell click', () => {
    render(<DataTransformGrid data={mockData} sourceId="abc" onTransform={vi.fn()} />)
    fireEvent.click(screen.getByText('Alice'))
    expect(screen.getByDisplayValue('Alice')).toBeDefined()
  })

  it('shows column dropdown menu on header click', () => {
    render(<DataTransformGrid data={mockData} sourceId="abc" onTransform={vi.fn()} />)
    // Click the dropdown trigger on the 'name' column header
    const headers = screen.getAllByRole('columnheader')
    fireEvent.click(headers[0].querySelector('button')!)
    expect(screen.getByText('Rename')).toBeDefined()
    expect(screen.getByText('Delete')).toBeDefined()
  })

  it('calls onTransform when cell is edited', async () => {
    const onTransform = vi.fn()
    render(<DataTransformGrid data={mockData} sourceId="abc" onTransform={onTransform} />)
    fireEvent.click(screen.getByText('Alice'))
    const input = screen.getByDisplayValue('Alice')
    fireEvent.change(input, { target: { value: 'Alicia' } })
    fireEvent.blur(input)
    expect(onTransform).toHaveBeenCalledWith('edit-cell', { row: 0, column: 'name', value: 'Alicia' })
  })
})
```

**Step 2: Implement DataTransformGrid**

Create `app/src/components/editor/DataTransformGrid.tsx`:

```tsx
import { useState, useCallback } from 'react'

interface TransformData {
  columns: string[]
  rows: Record<string, unknown>[]
  row_count: number
}

interface DataTransformGridProps {
  data: TransformData
  sourceId: string
  onTransform: (action: string, params: Record<string, unknown>) => Promise<void>
}

export function DataTransformGrid({ data, sourceId, onTransform }: DataTransformGridProps) {
  const [editingCell, setEditingCell] = useState<{ row: number; col: string } | null>(null)
  const [editValue, setEditValue] = useState('')
  const [menuCol, setMenuCol] = useState<string | null>(null)

  const handleCellClick = useCallback((row: number, col: string, value: string) => {
    setEditingCell({ row, col })
    setEditValue(value)
  }, [])

  const handleCellBlur = useCallback(async () => {
    if (!editingCell) return
    await onTransform('edit-cell', {
      row: editingCell.row,
      column: editingCell.col,
      value: editValue,
    })
    setEditingCell(null)
  }, [editingCell, editValue, onTransform])

  const handleColumnAction = useCallback(async (col: string, action: string) => {
    setMenuCol(null)
    switch (action) {
      case 'delete':
        await onTransform('delete-column', { column: col })
        break
      case 'rename': {
        const newName = prompt('New column name:', col)
        if (newName && newName !== col) {
          await onTransform('rename-column', { old: col, new: newName })
        }
        break
      }
      case 'round': {
        const decimals = prompt('Round to N decimals:', '2')
        if (decimals != null) {
          await onTransform('round', { column: col, decimals: parseInt(decimals) })
        }
        break
      }
      // Additional actions: cast-type, prepend-append
    }
  }, [onTransform])

  return (
    <div className="overflow-auto border border-border-default rounded-lg">
      {/* Toolbar */}
      <div className="flex gap-2 p-2 border-b border-border-default bg-surface-secondary">
        <button
          onClick={() => onTransform('transpose', {})}
          className="px-2 py-1 text-xs border border-border-default rounded hover:bg-surface-tertiary"
        >
          Transpose
        </button>
      </div>

      {/* Data grid */}
      <table className="w-full text-sm">
        <thead>
          <tr>
            {data.columns.map((col) => (
              <th
                key={col}
                role="columnheader"
                className="relative px-3 py-2 border-b border-border-default font-medium text-left bg-surface-secondary"
              >
                <div className="flex items-center justify-between">
                  <span>{col}</span>
                  <button
                    onClick={() => setMenuCol(menuCol === col ? null : col)}
                    className="ml-1 px-1 text-text-muted hover:text-text-primary"
                  >
                    ▾
                  </button>
                </div>
                {/* Dropdown menu */}
                {menuCol === col && (
                  <div className="absolute top-full left-0 z-10 mt-1 bg-white border border-border-default rounded-md shadow-lg py-1 min-w-[120px]">
                    <button onClick={() => handleColumnAction(col, 'rename')} className="block w-full text-left px-3 py-1 text-xs hover:bg-surface-secondary">Rename</button>
                    <button onClick={() => handleColumnAction(col, 'delete')} className="block w-full text-left px-3 py-1 text-xs hover:bg-surface-secondary text-red-600">Delete</button>
                    <button onClick={() => handleColumnAction(col, 'round')} className="block w-full text-left px-3 py-1 text-xs hover:bg-surface-secondary">Round...</button>
                  </div>
                )}
              </th>
            ))}
          </tr>
        </thead>
        <tbody>
          {data.rows.map((row, ri) => (
            <tr key={ri} className="hover:bg-surface-secondary">
              {data.columns.map((col) => {
                const val = String(row[col] ?? '')
                const isEditing = editingCell?.row === ri && editingCell?.col === col
                return (
                  <td
                    key={col}
                    className="px-3 py-1.5 border-b border-border-subtle cursor-text"
                    onClick={() => !isEditing && handleCellClick(ri, col, val)}
                  >
                    {isEditing ? (
                      <input
                        autoFocus
                        value={editValue}
                        onChange={(e) => setEditValue(e.target.value)}
                        onBlur={handleCellBlur}
                        onKeyDown={(e) => e.key === 'Enter' && handleCellBlur()}
                        className="w-full px-1 py-0 text-sm border border-blue-400 rounded outline-none"
                      />
                    ) : (
                      val
                    )}
                  </td>
                )
              })}
            </tr>
          ))}
        </tbody>
      </table>
    </div>
  )
}
```

**Step 3: Run tests**

Run: `cd app && npx vitest run src/tests/data-transforms.test.tsx`
Expected: PASS

**Step 4: Commit**

```bash
git commit -m "feat: add DataTransformGrid component with inline editing and column operations"
```

---

### Task N.4: Integrate Transform Grid into Editor

**Files:**
- Modify: `app/src/pages/EditorPage.tsx` (lines 322-390)

**Step 1: Add a "Transform Data" tab or toggle**

In the editor layout, add a toggle between "Chart" and "Transform Data" views. When "Transform Data" is active, show the DataTransformGrid instead of the chart preview.

Wire the `onTransform` callback to call the appropriate dataStore method, which calls the backend and returns the updated preview.

**Step 2: Run all tests**

Run: `cd app && npx vitest run`
Expected: All pass

**Step 3: Commit**

```bash
git commit -m "feat: integrate DataTransformGrid into EditorPage with view toggle"
```

---

## Session O: Edit History / Versioning

**Files:**
- Create: `api/services/version_storage.py`
- Create: `api/routers/versions.py`
- Create: `api/tests/test_versions.py`
- Create: `app/src/components/editor/VersionHistoryPanel.tsx`
- Create: `app/src/tests/version-history.test.tsx`
- Modify: `api/main.py` (add router)
- Modify: `api/services/chart_storage.py` (lines 176-205: update_chart)
- Modify: `app/src/stores/editorStore.ts` (lines 764-845: save, lines 985-1016: publishChart)
- Modify: `app/src/pages/EditorPage.tsx` (lines 236-312: header)

### Task O.1: Backend Version Storage Service

**Step 1: Write failing tests**

Create `api/tests/test_versions.py`:

```python
import pytest
from pathlib import Path
import json


class TestVersionStorage:
    def test_create_version(self, client, sample_chart_id):
        resp = client.post(
            f"/api/v2/charts/{sample_chart_id}/versions",
            json={"trigger": "manual"},
        )
        assert resp.status_code == 200
        data = resp.json()
        assert data["version"] == 1
        assert data["trigger"] == "manual"

    def test_list_versions(self, client, sample_chart_id):
        # Create 3 versions
        for trigger in ["manual", "auto", "publish"]:
            client.post(f"/api/v2/charts/{sample_chart_id}/versions", json={"trigger": trigger})
        resp = client.get(f"/api/v2/charts/{sample_chart_id}/versions")
        assert resp.status_code == 200
        versions = resp.json()
        assert len(versions) == 3
        assert versions[0]["version"] == 1
        assert versions[2]["version"] == 3

    def test_get_version_content(self, client, sample_chart_id):
        client.post(f"/api/v2/charts/{sample_chart_id}/versions", json={"trigger": "manual"})
        resp = client.get(f"/api/v2/charts/{sample_chart_id}/versions/1")
        assert resp.status_code == 200
        data = resp.json()
        assert "title" in data  # Full chart content

    def test_restore_version(self, client, sample_chart_id):
        # Create version, modify chart, restore
        client.post(f"/api/v2/charts/{sample_chart_id}/versions", json={"trigger": "manual"})
        client.put(f"/api/v2/charts/{sample_chart_id}", json={"title": "Modified Title"})
        resp = client.post(f"/api/v2/charts/{sample_chart_id}/versions/1/restore")
        assert resp.status_code == 200
        # Verify chart reverted
        chart = client.get(f"/api/v2/charts/{sample_chart_id}").json()
        assert chart["chart"]["title"] != "Modified Title"

    def test_delete_version(self, client, sample_chart_id):
        client.post(f"/api/v2/charts/{sample_chart_id}/versions", json={"trigger": "manual"})
        resp = client.delete(f"/api/v2/charts/{sample_chart_id}/versions/1")
        assert resp.status_code == 200
        listing = client.get(f"/api/v2/charts/{sample_chart_id}/versions").json()
        assert len(listing) == 0

    def test_prune_at_50_versions(self, client, sample_chart_id):
        for i in range(55):
            client.post(f"/api/v2/charts/{sample_chart_id}/versions", json={"trigger": "auto"})
        listing = client.get(f"/api/v2/charts/{sample_chart_id}/versions").json()
        assert len(listing) == 50  # Oldest 5 pruned

    def test_version_not_found(self, client, sample_chart_id):
        resp = client.get(f"/api/v2/charts/{sample_chart_id}/versions/999")
        assert resp.status_code == 404

    def test_chart_not_found(self, client):
        resp = client.get("/api/v2/charts/nonexistent/versions")
        assert resp.status_code == 404
```

**Step 2: Implement version_storage.py**

Create `api/services/version_storage.py`:

```python
"""Chart version storage — snapshot management with auto-pruning."""
from __future__ import annotations

import json
from dataclasses import dataclass
from datetime import datetime, timezone
from pathlib import Path

VERSIONS_DIR = Path(__file__).resolve().parent.parent.parent / "data" / "versions"
MAX_VERSIONS = 50


@dataclass
class VersionMeta:
    version: int
    created_at: str
    trigger: str  # "auto" | "publish" | "manual"
    label: str | None = None


def _chart_versions_dir(chart_id: str) -> Path:
    d = VERSIONS_DIR / chart_id
    d.mkdir(parents=True, exist_ok=True)
    return d


def create_version(chart_id: str, chart_data: dict, trigger: str, label: str | None = None) -> VersionMeta:
    d = _chart_versions_dir(chart_id)
    existing = list_versions(chart_id)
    version_num = (existing[-1].version + 1) if existing else 1

    meta = VersionMeta(
        version=version_num,
        created_at=datetime.now(timezone.utc).isoformat(),
        trigger=trigger,
        label=label,
    )

    snapshot = {
        **chart_data,
        "_version_meta": {
            "version": meta.version,
            "created_at": meta.created_at,
            "trigger": meta.trigger,
            "label": meta.label,
        },
    }

    path = d / f"{version_num}.json"
    tmp = path.with_suffix(".tmp")
    with open(tmp, "w") as f:
        json.dump(snapshot, f, indent=2)
    tmp.rename(path)

    # Prune oldest if over limit
    _prune(chart_id)

    return meta


def list_versions(chart_id: str) -> list[VersionMeta]:
    d = VERSIONS_DIR / chart_id
    if not d.exists():
        return []
    versions = []
    for p in sorted(d.glob("*.json"), key=lambda p: int(p.stem)):
        with open(p) as f:
            data = json.load(f)
        vm = data.get("_version_meta", {})
        versions.append(VersionMeta(
            version=int(p.stem),
            created_at=vm.get("created_at", ""),
            trigger=vm.get("trigger", "unknown"),
            label=vm.get("label"),
        ))
    return versions


def get_version(chart_id: str, version: int) -> dict | None:
    path = VERSIONS_DIR / chart_id / f"{version}.json"
    if not path.exists():
        return None
    with open(path) as f:
        data = json.load(f)
    data.pop("_version_meta", None)
    return data


def delete_version(chart_id: str, version: int) -> bool:
    path = VERSIONS_DIR / chart_id / f"{version}.json"
    if not path.exists():
        return False
    path.unlink()
    return True


def _prune(chart_id: str):
    versions = list_versions(chart_id)
    while len(versions) > MAX_VERSIONS:
        oldest = versions.pop(0)
        delete_version(chart_id, oldest.version)
```

**Step 3: Implement versions router**

Create `api/routers/versions.py`:

```python
"""Version history endpoints for charts."""
from __future__ import annotations

from fastapi import APIRouter, HTTPException
from pydantic import BaseModel

from ..services import chart_storage, version_storage

router = APIRouter(prefix="/v2/charts", tags=["versions"])


class CreateVersionRequest(BaseModel):
    trigger: str  # "auto" | "publish" | "manual"
    label: str | None = None


@router.post("/{chart_id}/versions")
async def create_version(chart_id: str, req: CreateVersionRequest):
    chart = chart_storage.get_chart(chart_id)
    if not chart:
        raise HTTPException(404, f"Chart {chart_id} not found")
    from dataclasses import asdict
    chart_data = asdict(chart)
    meta = version_storage.create_version(chart_id, chart_data, req.trigger, req.label)
    return {"version": meta.version, "created_at": meta.created_at, "trigger": meta.trigger, "label": meta.label}


@router.get("/{chart_id}/versions")
async def list_versions(chart_id: str):
    chart = chart_storage.get_chart(chart_id)
    if not chart:
        raise HTTPException(404, f"Chart {chart_id} not found")
    versions = version_storage.list_versions(chart_id)
    return [{"version": v.version, "created_at": v.created_at, "trigger": v.trigger, "label": v.label} for v in versions]


@router.get("/{chart_id}/versions/{version}")
async def get_version(chart_id: str, version: int):
    data = version_storage.get_version(chart_id, version)
    if not data:
        raise HTTPException(404, f"Version {version} not found")
    return data


@router.post("/{chart_id}/versions/{version}/restore")
async def restore_version(chart_id: str, version: int):
    data = version_storage.get_version(chart_id, version)
    if not data:
        raise HTTPException(404, f"Version {version} not found")
    # Restore: update chart with version's fields
    chart_storage.update_chart(
        chart_id,
        chart_type=data.get("chart_type"),
        title=data.get("title"),
        subtitle=data.get("subtitle"),
        source=data.get("source"),
        x=data.get("x"),
        y=data.get("y"),
        series=data.get("series"),
        horizontal=data.get("horizontal"),
        sort=data.get("sort"),
        config=data.get("config"),
    )
    return {"restored": True, "version": version}


@router.delete("/{chart_id}/versions/{version}")
async def delete_version(chart_id: str, version: int):
    if not version_storage.delete_version(chart_id, version):
        raise HTTPException(404, f"Version {version} not found")
    return {"deleted": True}
```

Register in `api/main.py`:
```python
from .routers.versions import router as versions_router
app.include_router(versions_router, prefix="/api")
```

**Step 4: Run tests**

Run: `cd api && python -m pytest tests/test_versions.py -v`
Expected: PASS (8 tests)

**Step 5: Commit**

```bash
git commit -m "feat: add version storage service and version CRUD endpoints"
```

---

### Task O.2: Frontend Auto-Save Logic

**Files:**
- Modify: `app/src/stores/editorStore.ts`

**Step 1: Add version tracking to editorStore**

Add to the store:

```typescript
// Version tracking state
_saveCount: 0,
_idleTimer: null as ReturnType<typeof setTimeout> | null,

// Increment save count, auto-snapshot every 30 saves
_trackSave: async () => {
  const state = get()
  const count = state._saveCount + 1
  set({ _saveCount: count })

  if (count % 30 === 0 && state.chartId) {
    await fetch(`/api/v2/charts/${state.chartId}/versions`, {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({ trigger: 'auto' }),
    })
  }
},

// Reset idle timer on each save — snapshot after 60s idle
_resetIdleTimer: () => {
  const state = get()
  if (state._idleTimer) clearTimeout(state._idleTimer)
  const timer = setTimeout(async () => {
    if (state.chartId) {
      await fetch(`/api/v2/charts/${state.chartId}/versions`, {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ trigger: 'auto' }),
      })
    }
  }, 60_000)
  set({ _idleTimer: timer })
},

// Manual save version
saveVersion: async () => {
  const { chartId } = get()
  if (!chartId) return
  await fetch(`/api/v2/charts/${chartId}/versions`, {
    method: 'POST',
    headers: { 'Content-Type': 'application/json' },
    body: JSON.stringify({ trigger: 'manual' }),
  })
},
```

Wire `_trackSave()` and `_resetIdleTimer()` into the existing `save()` function (line ~764).

Wire auto-version on publish into `publishChart()` (line ~985):
```typescript
// After successful publish, create version
await fetch(`/api/v2/charts/${chartId}/versions`, {
  method: 'POST',
  headers: { 'Content-Type': 'application/json' },
  body: JSON.stringify({ trigger: 'publish' }),
})
```

**Step 2: Commit**

```bash
git commit -m "feat: add auto-save version tracking to editorStore (30-save + 60s idle + publish)"
```

---

### Task O.3: VersionHistoryPanel Component

**Files:**
- Create: `app/src/components/editor/VersionHistoryPanel.tsx`
- Create: `app/src/tests/version-history.test.tsx`

**Step 1: Write failing tests**

```tsx
import { describe, it, expect, vi } from 'vitest'
import { render, screen } from '@testing-library/react'

describe('VersionHistoryPanel', () => {
  it('renders version list', () => {
    const versions = [
      { version: 1, created_at: '2026-02-24T10:00:00Z', trigger: 'manual', label: null },
      { version: 2, created_at: '2026-02-24T11:00:00Z', trigger: 'auto', label: null },
      { version: 3, created_at: '2026-02-24T12:00:00Z', trigger: 'publish', label: null },
    ]
    render(<VersionHistoryPanel chartId="abc" versions={versions} onRestore={vi.fn()} onClose={vi.fn()} />)
    expect(screen.getByText('v1')).toBeDefined()
    expect(screen.getByText('v2')).toBeDefined()
    expect(screen.getByText('v3')).toBeDefined()
  })

  it('shows trigger badges', () => {
    const versions = [
      { version: 1, created_at: '2026-02-24T10:00:00Z', trigger: 'publish', label: null },
    ]
    render(<VersionHistoryPanel chartId="abc" versions={versions} onRestore={vi.fn()} onClose={vi.fn()} />)
    expect(screen.getByText('publish')).toBeDefined()
  })

  it('shows empty state', () => {
    render(<VersionHistoryPanel chartId="abc" versions={[]} onRestore={vi.fn()} onClose={vi.fn()} />)
    expect(screen.getByText(/no versions/i)).toBeDefined()
  })
})
```

**Step 2: Implement VersionHistoryPanel**

A sidebar/modal component that lists versions chronologically, shows trigger badges, and has restore buttons with confirmation.

**Step 3: Integrate into EditorPage**

Add "History" button to editor header (near publish button, line ~289). Opens VersionHistoryPanel as a right sidebar or modal.

Add "Save Version" button next to it.

Update publish button label: show "Republish" when `status === 'published'`.

**Step 4: Run tests + commit**

```bash
git commit -m "feat: add VersionHistoryPanel with restore flow and editor integration"
```

---

## Session P: "Get the Data" CSV Download

**Files:**
- Modify: `api/routers/charts_v2.py` (add CSV endpoint)
- Create: `api/tests/test_csv_download.py`
- Modify: `app/src/types/chart.ts` (add allowDataDownload)
- Modify: `app/src/stores/editorStore.ts` (map allowDataDownload)
- Modify: `app/src/pages/EmbedChartPage.tsx` (add download link)
- Modify: `app/src/pages/EmbedDashboardPage.tsx` (add per-chart link)
- Modify: `app/src/components/charts/ChartWrapper.tsx` (add CSV export button)
- Modify: `app/src/components/editor/Toolbox.tsx` (add toggle)
- Create: `app/src/tests/csv-download.test.tsx`

### Task P.1: Backend CSV Endpoint

**Step 1: Write failing tests**

Create `api/tests/test_csv_download.py`:

```python
import pytest


class TestCSVDownload:
    def test_download_csv(self, client, sample_chart_id):
        resp = client.get(f"/api/v2/charts/{sample_chart_id}/data.csv")
        assert resp.status_code == 200
        assert resp.headers["content-type"] == "text/csv; charset=utf-8"
        assert "attachment" in resp.headers["content-disposition"]
        # Verify CSV content has header row + data rows
        lines = resp.text.strip().split("\n")
        assert len(lines) >= 2  # header + at least 1 data row

    def test_csv_filename_from_title(self, client, sample_chart_id):
        resp = client.get(f"/api/v2/charts/{sample_chart_id}/data.csv")
        assert ".csv" in resp.headers["content-disposition"]

    def test_csv_403_when_disabled(self, client, sample_chart_id):
        # Update chart config to disable download
        client.put(
            f"/api/v2/charts/{sample_chart_id}",
            json={"config": {"allowDataDownload": False}},
        )
        resp = client.get(f"/api/v2/charts/{sample_chart_id}/data.csv")
        assert resp.status_code == 403

    def test_csv_404_for_missing_chart(self, client):
        resp = client.get("/api/v2/charts/nonexistent/data.csv")
        assert resp.status_code == 404

    def test_csv_published_no_auth(self, client, published_chart_id):
        resp = client.get(f"/api/v2/charts/{published_chart_id}/data.csv")
        assert resp.status_code == 200
```

**Step 2: Implement CSV endpoint**

Add to `api/routers/charts_v2.py`:

```python
from fastapi.responses import StreamingResponse
import csv
import io

@router.get("/{chart_id}/data.csv")
async def download_csv(chart_id: str):
    """Download chart data as CSV file."""
    chart = chart_storage.get_chart(chart_id)
    if not chart:
        raise HTTPException(404, f"Chart {chart_id} not found")

    # Check if download is allowed
    config = chart.config or {}
    if config.get("allowDataDownload") is False:
        raise HTTPException(403, "Data download is disabled for this chart")

    # Execute chart SQL to get data
    result = duckdb_svc.execute_query(chart.sql, chart.source_id)

    # Build CSV in memory
    output = io.StringIO()
    writer = csv.DictWriter(output, fieldnames=result.columns)
    writer.writeheader()
    writer.writerows(result.rows)

    filename = f"{chart.title or 'data'}.csv".replace('"', '')

    return StreamingResponse(
        iter([output.getvalue()]),
        media_type="text/csv",
        headers={"Content-Disposition": f'attachment; filename="{filename}"'},
    )
```

**Step 3: Run tests**

Run: `cd api && python -m pytest tests/test_csv_download.py -v`
Expected: PASS (5 tests)

**Step 4: Commit**

```bash
git commit -m "feat: add GET /v2/charts/{id}/data.csv endpoint with configurable access"
```

---

### Task P.2: allowDataDownload Config Toggle

**Step 1: Add to ChartConfig**

In `app/src/types/chart.ts` (line ~294), add:
```typescript
  /** Enable CSV download button in embeds and public page */
  allowDataDownload?: boolean
```

**Step 2: Add to EditorConfig and save/load**

In `app/src/stores/editorStore.ts`:
- Add `allowDataDownload: boolean` to EditorConfig
- Default: `true` in DEFAULT_CONFIG
- Map in loadChart, saveNew, save

**Step 3: Add toggle in Toolbox**

In the Toolbox component, add under a "Sharing" section:

```tsx
<label className="flex items-center gap-2">
  <input
    type="checkbox"
    checked={config.allowDataDownload !== false}
    onChange={(e) => updateConfig({ allowDataDownload: e.target.checked })}
  />
  <span className="text-xs">Allow data download</span>
</label>
```

**Step 4: Commit**

```bash
git commit -m "feat: add allowDataDownload config toggle in Toolbox"
```

---

### Task P.3: Frontend Download Links

**Step 1: Write failing tests**

Create `app/src/tests/csv-download.test.tsx`:

```tsx
describe('CSV download link', () => {
  it('shows "Get the data" link when allowDataDownload is true', () => {
    // Render EmbedChartPage with chart that has allowDataDownload: true
    // Assert link is visible
  })

  it('hides link when allowDataDownload is false', () => {
    // Render with allowDataDownload: false
    // Assert link not in DOM
  })

  it('hides link when plain=true', () => {
    // Render with ?plain=true
    // Assert link not in DOM
  })

  it('CSV button appears in ChartWrapper export row', () => {
    // Render ChartWrapper
    // Assert "CSV" button exists alongside SVG/PNG/PDF/PPTX
  })
})
```

**Step 2: Add link to EmbedChartPage**

After the source line (line ~264), add:

```tsx
{!flags.plain && chart.config?.allowDataDownload !== false && (
  <a
    href={`/api/v2/charts/${chartId}/data.csv`}
    download
    style={{
      display: 'inline-block',
      marginTop: 4,
      fontSize: 11,
      color: isDark ? '#64748b' : '#999',
      textDecoration: 'underline',
    }}
  >
    Get the data
  </a>
)}
```

**Step 3: Add CSV button to ChartWrapper**

In `ChartWrapper.tsx`, add "CSV" to the export button row:

```tsx
// Add handler:
const handleExportCSV = useCallback(() => {
  if (!chartId) return
  window.open(`/api/v2/charts/${chartId}/data.csv`, '_blank')
}, [chartId])

// Add button alongside existing SVG/PNG/PDF/PPTX:
{['SVG', 'PNG', 'PDF', 'PPTX', 'CSV'].map((fmt) => (
  // ... existing button pattern, add CSV to the onClick mapping
))}
```

Note: ChartWrapper will need to receive `chartId` as a prop. Check if it already has it; if not, pass it from EditorPage.

**Step 4: Add to EmbedDashboardPage**

Pass `allowDataDownload` through DashboardGrid to each chart cell.

**Step 5: Run tests**

Run: `cd app && npx vitest run src/tests/csv-download.test.tsx`
Expected: PASS

**Step 6: Commit**

```bash
git commit -m "feat: add 'Get the data' CSV links to embed pages, editor, and public page"
```

---

## Merge & Verify

After all 3 sessions complete:

1. Merge P → main (smallest, fewest conflicts)
2. Merge O → main
3. Merge N → main (largest, most files)
4. Run full test suite: `cd app && npx vitest run` + `cd api && python -m pytest`
5. Verify test count is ~762 (705 existing + ~57 new)
6. Update `tasks/todo.md` with Phase 8 section
7. Update `memory/MEMORY.md` and `memory/remaining-gaps.md`
